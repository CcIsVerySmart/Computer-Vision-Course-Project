# -*- coding: utf-8 -*-
import os
import tempfile
import cv2
import PIL.Image
import streamlit as st
from ultralytics import YOLO

# ğŸš¨ å¿…é¡»ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤
st.set_page_config(page_title="çº¢å¤–æ— äººæœºæ£€æµ‹ç³»ç»Ÿ", layout="wide")

# ====================== åŸºç¡€é…ç½® ======================
MODEL_PATH = r"C:\Users\13579\Desktop\cv\weights\best_wyc.pt"

# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_model():
    return YOLO(MODEL_PATH)

model = load_model()

# ====================== é¡µé¢æ ‡é¢˜å’Œè¯´æ˜ ======================
st.title("ğŸš YOLOv8 çº¢å¤–æ— äººæœºæ•°é‡æ£€æµ‹ç³»ç»Ÿ")

st.markdown("""
æœ¬ç³»ç»ŸåŸºäº **YOLOv8 + Streamlit** å®ç°ï¼Œæ”¯æŒæ— äººæœºç›®æ ‡æ£€æµ‹çš„ **å›¾ç‰‡æ£€æµ‹** ä¸ **è§†é¢‘æ£€æµ‹** ä¸¤ç§æ¨¡å¼ã€‚  
æ‚¨å¯ä»¥é€šè¿‡å·¦ä¾§å‚æ•°æ è°ƒæ•´æ£€æµ‹ç½®ä¿¡åº¦ï¼Œä¸Šä¼ å›¾ç‰‡æˆ–è§†é¢‘åç‚¹å‡» **å¼€å§‹æ£€æµ‹** æŒ‰é’®ï¼Œå³å¯æŸ¥çœ‹æ£€æµ‹æ•ˆæœã€‚  

ğŸ“Œ **ä½¿ç”¨æŒ‡å—ï¼š**  
1. åœ¨å·¦ä¾§ **å‚æ•°é…ç½®æ ** è°ƒæ•´æ£€æµ‹ç½®ä¿¡åº¦ï¼ˆæ•°å€¼è¶Šé«˜ï¼Œæ£€æµ‹è¶Šä¸¥æ ¼ï¼‰ã€‚  
2. åœ¨å·¦ä¾§é€‰æ‹©æ£€æµ‹æ¨¡å¼ï¼š**å›¾ç‰‡æ£€æµ‹** æˆ– **è§†é¢‘æ£€æµ‹**ã€‚  
3. ç‚¹å‡»ä¸­é—´åŒºåŸŸä¸Šä¼ æ–‡ä»¶ï¼ˆæ”¯æŒå¸¸è§æ ¼å¼ï¼šJPGã€PNGã€MP4 ç­‰ï¼‰ã€‚  
4. ç‚¹å‡» **å¼€å§‹æ£€æµ‹** æŒ‰é’®ï¼Œç»“æœå°†åœ¨ç•Œé¢å³ä¾§å±•ç¤ºï¼Œå¹¶å¯ä¸‹è½½ä¿å­˜ã€‚  

âš ï¸ æ³¨æ„ï¼šä¸Šä¼ æ–‡ä»¶å¤§å°éœ€å°äº **200MB**ã€‚
""")

st.sidebar.header("âš™ï¸ å‚æ•°é…ç½®")
confidence = st.sidebar.slider("æ£€æµ‹ç½®ä¿¡åº¦", 0.25, 1.0, 0.5, 0.01)

mode = st.sidebar.radio("é€‰æ‹©æ¨¡å¼", ["å›¾ç‰‡æ£€æµ‹", "è§†é¢‘æ£€æµ‹"])

# ====================== å›¾ç‰‡æ£€æµ‹ ======================
if mode == "å›¾ç‰‡æ£€æµ‹":
    uploaded_img = st.file_uploader("ğŸ“· ä¸Šä¼ å›¾ç‰‡", type=["jpg", "jpeg", "png", "bmp", "webp"])

    if uploaded_img is not None:
        image = PIL.Image.open(uploaded_img)

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ–¼ï¸ åŸå§‹å›¾ç‰‡")
            st.image(image, use_container_width=True)

        with col2:
            st.subheader("ğŸ¯ æ£€æµ‹ç»“æœ")
            if "detected_img" in st.session_state:
                st.image(st.session_state["detected_img"], use_container_width=True)
                st.success(f"âœ… æ£€æµ‹å®Œæˆï¼Œå…±æ£€æµ‹åˆ°ç›®æ ‡æ•°é‡: **{st.session_state['detected_count']}** æ¶æ— äººæœº")

                # ä¸‹è½½æŒ‰é’®
                with open("detected_result.jpg", "wb") as f:
                    f.write(cv2.imencode(".jpg", st.session_state["detected_img"])[1].tobytes())
                with open("detected_result.jpg", "rb") as f:
                    st.download_button("ğŸ’¾ ä¸‹è½½æ£€æµ‹ç»“æœå›¾ç‰‡", f, file_name="detected_result.jpg")

            else:
                st.info("è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹æ£€æµ‹")

        # æ£€æµ‹æŒ‰é’®æ”¾åˆ°ä¸‹æ–¹å±…ä¸­
        btn_col = st.columns([1, 2, 1])
        with btn_col[1]:
            if st.button("ğŸš€ å¼€å§‹æ£€æµ‹", use_container_width=True):
                results = model.predict(image, conf=confidence)
                res_plot = results[0].plot()
                st.session_state["detected_img"] = res_plot
                st.session_state["detected_count"] = len(results[0].boxes)
                st.rerun()

# ====================== è§†é¢‘æ£€æµ‹ ======================
elif mode == "è§†é¢‘æ£€æµ‹":
    uploaded_vid = st.file_uploader("ğŸ¥ ä¸Šä¼ è§†é¢‘", type=["mp4", "avi", "mov", "mkv"])

    if uploaded_vid is not None:
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_vid.read())

        st.markdown("### ğŸ” æ£€æµ‹è¿‡ç¨‹")
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ“¹ åŸå§‹è§†é¢‘å¸§")
            raw_frame_placeholder = st.empty()   # åŸå§‹å¸§å ä½ç¬¦

        with col2:
            st.subheader("ğŸ¯ æ£€æµ‹ç»“æœå¸§")
            det_frame_placeholder = st.empty()   # æ£€æµ‹å¸§å ä½ç¬¦
            info_box = st.empty()

        # æ£€æµ‹æŒ‰é’®æ”¾åˆ°ä¸‹æ–¹å±…ä¸­
        btn_col = st.columns([1, 2, 1])
        with btn_col[1]:
            if st.button("ğŸš€ å¼€å§‹æ£€æµ‹", use_container_width=True):
                cap = cv2.VideoCapture(tfile.name)
                frame_count = 0
                total_objects = 0

                # ä¿å­˜æ£€æµ‹ç»“æœè§†é¢‘
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                out_path = "detected_video.mp4"
                out = cv2.VideoWriter(out_path, fourcc, cap.get(cv2.CAP_PROP_FPS),
                                      (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                                       int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))

                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret:
                        break

                    frame_count += 1
                    # æ¨ç†
                    results = model.predict(frame, conf=confidence, verbose=False)
                    res_plotted = results[0].plot()

                    # å½“å‰å¸§ç›®æ ‡æ•°é‡
                    current_count = len(results[0].boxes)
                    total_objects += current_count

                    # å·¦è¾¹æ˜¾ç¤ºåŸå§‹å¸§
                    raw_frame_placeholder.image(frame, channels="BGR", use_container_width=True)
                    # å³è¾¹æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                    det_frame_placeholder.image(res_plotted, channels="BGR", use_container_width=True)

                    # å¸§ä¿¡æ¯
                    info_box.info(f"å¸§ {frame_count} - æ£€æµ‹åˆ°ç›®æ ‡æ•°é‡: {current_count}")

                    # ä¿å­˜æ£€æµ‹å¸§åˆ°è§†é¢‘
                    out.write(res_plotted)

                cap.release()
                out.release()

                st.success(f"âœ… æ£€æµ‹å®Œæˆï¼Œæ€»å¸§æ•°: {frame_count}, ç´¯è®¡æ£€æµ‹ç›®æ ‡æ•°é‡: {total_objects}")

                # æä¾›ä¸‹è½½æŒ‰é’®
                with open(out_path, "rb") as f:
                    st.download_button("ğŸ’¾ ä¸‹è½½æ£€æµ‹ç»“æœè§†é¢‘", f, file_name="detected_video.mp4")
